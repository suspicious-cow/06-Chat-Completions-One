{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Completions One\n",
    "\n",
    "## Basic Connection and Packages\n",
    "\n",
    "### Importing OpenAI and Initializing the Client\n",
    "\n",
    "To begin, we'll import the `OpenAI` class from the `openai` library, which allows us to interact with the OpenAI API. Next, we initialize a client instance, which we'll use to send requests and receive responses from the OpenAI models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is a simple example of using the OpenAI API\n",
    "It uses the OpenAI Python client library to open a connection to the OpenAI API.\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Additional Libraries\n",
    "\n",
    "Next, we import the `json` library. This standard Python library helps us handle JSON data, allowing easy conversion between JSON strings and Python data structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Additional imports\n",
    "These imports are used for various purposes in the script.\n",
    "\"\"\"\n",
    "\n",
    "import json # common library for working with JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "### Creating a Chat Completion with OpenAI API\n",
    "\n",
    "Now, we'll demonstrate how to use the OpenAI API to generate text completions. We'll utilize the previously initialized client to send a prompt to the `gpt-4o-mini` model—a compact variant of the GPT-4 model optimized for efficient performance. \n",
    "\n",
    "In this example, we define two roles with messages within our prompt:\n",
    "\n",
    "- **System**: Sets the behavior of the model, instructing it to act as a helpful assistant.\n",
    "- **User**: Provides a specific request—in this case, asking the model to write a haiku about recursion in programming.\n",
    "\n",
    "After sending this prompt, we print the model's response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code calls itself back,  \n",
      "Endless loops in logic's dance,  \n",
      "Fractals of the mind.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `gpt-4o-mini` model, which is a variant of the GPT-4 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating to the Newer Model Types and Message Roles\n",
    "\n",
    "In this example, we demonstrate using the newer OpenAI model `o3-mini`. Notably, this model variant introduces a new role called `developer`, replacing the previous `system` role. \n",
    "\n",
    "The updated roles are:\n",
    "\n",
    "- **Developer**: Provides instructions defining the assistant's behavior.\n",
    "- **User**: Specifies the actual query or request—in this case, generating a haiku about recursion in programming.\n",
    "\n",
    "We send these messages to the `o3-mini` model and output the generated response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive function  \n",
      "calls itself in endless loop  \n",
      "base case ends the dance\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `o3-mini` model, which is a variant of the o3 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"o3-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the Response Format\n",
    "\n",
    "Next, we add the `response_format` parameter to our request, allowing explicit control over how the API returns the response. Here, we specify `\"text\"` to ensure the model's response is returned as plain text, suitable for direct use or printing.\n",
    "\n",
    "We continue to use the `gpt-4o-mini` model and the newer `developer` role to instruct the assistant's behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In endless loops bound,  \n",
      "Code calls itself once again,  \n",
      "Solutions unfold.  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in text format.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Responses in JSON Format\n",
    "\n",
    "In this example, we demonstrate how to explicitly request the model’s response as a structured JSON object using the `response_format` parameter set to `\"json_object\"`. This format is particularly useful when you want to parse and integrate the model's responses programmatically into applications or data pipelines.\n",
    "\n",
    "We continue using the `gpt-4o-mini` model and clearly instruct it (via the user message) to generate the response as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"haiku\": {\n",
      "    \"line1\": \"Endless calls unfold,\",\n",
      "    \"line2\": \"Each step a loop back in time,\",\n",
      "    \"line3\": \"Logic's dance in code.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON object format.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming. Give me the output in JSON format.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"json_object\"},  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Custom JSON Schema for Structured Responses\n",
    "\n",
    "In this example, we demonstrate how to obtain structured, schema-based JSON responses from the OpenAI API. We set the `response_format` parameter to `\"json_schema\"` and define our own schema. This custom schema precisely controls the structure and content of the generated response, making it easy to integrate into applications, databases, or analytical tools.\n",
    "\n",
    "Our custom JSON schema requests detailed, structured information about an animal—in this case, an emperor penguin—including:\n",
    "\n",
    "- **Name**: The common name of the animal.\n",
    "- **Species**: The species classification.\n",
    "- **Lifespan**: Typical lifespan in years.\n",
    "- **Minimum and Maximum Weight**: Typical weight range in kilograms.\n",
    "- **Habitat**: Natural habitat description.\n",
    "- **Diet**: Typical dietary habits.\n",
    "\n",
    "We then parse the returned JSON content into a Python dictionary and print it in a formatted, easy-to-read way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Emperor Penguin\",\n",
      "  \"species\": \"Aptenodytes forsteri\",\n",
      "  \"lifespan\": 15,\n",
      "  \"min_weight\": 22,\n",
      "  \"max_weight\": 45,\n",
      "  \"habitat\": \"Antarctic ice and surrounding waters\",\n",
      "  \"diet\": \"Carnivorous, primarily fish and squid\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON using a schema of our choice.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # Changed \"developer\" to \"system\"\n",
    "        {\"role\": \"user\", \"content\": \"What is an emperor penguin?\"}  # Added question mark to match content\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"animal_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The common name of the animal.\"\n",
    "                    },\n",
    "                    \"species\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The species classification of the animal.\"\n",
    "                    },\n",
    "                    \"lifespan\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The typical lifespan of the animal in years.\"\n",
    "                    },\n",
    "                    \"min_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The minimum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"max_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The maximum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"habitat\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The natural habitat where the animal is commonly found.\"\n",
    "                    },\n",
    "                    \"diet\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The dietary habits of the animal.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"name\",\n",
    "                    \"species\",\n",
    "                    \"lifespan\",\n",
    "                    \"min_weight\",\n",
    "                    \"max_weight\",\n",
    "                    \"habitat\",\n",
    "                    \"diet\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }  \n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Selection from Multiple JSON Schemas\n",
    "\n",
    "This example shows how the OpenAI API can dynamically select from multiple structured JSON schemas based on the user's prompt. Here, we've defined two distinct schemas within one request:\n",
    "\n",
    "- **Animal Schema**: Captures structured information about an animal, such as species, lifespan, and diet.\n",
    "- **House Schema**: Provides details about a house, including architectural style, size, and location.\n",
    "\n",
    "By asking the model to \"Describe a typical family home,\" the API automatically selects and uses the house schema to structure its response. The resulting JSON is then parsed and printed neatly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Modern\",\n",
      "    \"num_bedrooms\": 4,\n",
      "    \"num_bathrooms\": 3,\n",
      "    \"square_feet\": 2200,\n",
      "    \"location\": \"Suburban area\",\n",
      "    \"year_built\": 2015\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical family home.\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"item_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking a Questions About an Object Not Covered by a Schema\n",
    "\n",
    "If you ask a question about an object, say a car, the OpenAI API, given our current schema setup (with schemas only for animals and houses), will be forced to respond using one of the provided schemas. This typically results in one of two behaviors:\n",
    "\n",
    "Forced Schema Matching:\n",
    "The API might try to fit the response into one of the existing schemas, causing incorrect or nonsensical results. For example, it might awkwardly describe a car using house properties (e.g., treating \"square_feet\" as the car’s size), or as an animal (e.g., describing the car as an animal with a \"lifespan\" and \"diet\").\n",
    "\n",
    "Validation Error:\n",
    "Depending on how strictly you've configured schema validation (\"strict\": True), the API could also fail or produce an error because it cannot logically conform a car description to either the animal or house schemas.\n",
    "\n",
    "Recommended Approach:\n",
    "To handle queries like these effectively, you should either:\n",
    "\n",
    "Add an additional schema specifically for cars using another schema entry within anyOf, or\n",
    "Create a general schema (e.g., general_item) that can accommodate miscellaneous or undefined categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Sedan\",\n",
      "    \"num_bedrooms\": 0,\n",
      "    \"num_bathrooms\": 0,\n",
      "    \"square_feet\": 0,\n",
      "    \"location\": \"\",\n",
      "    \"year_built\": 2023\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical car.\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"item_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "### Controlling Creativity with the Temperature Parameter\n",
    "\n",
    "In this example, we introduce the `temperature` parameter to control the randomness and creativity of the model's responses. A lower temperature (e.g., `0`) produces deterministic, predictable outputs suitable for clear and consistent writing. A higher temperature (closer to `1`) yields more creative and varied responses.\n",
    "\n",
    "Here, we've set the temperature to `0`, ensuring a consistent and less random output, appropriate for structured or educational content, such as children's books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green forest, there lived a little frog named Freddie. Freddie was not just any ordinary frog; he had the brightest green skin that sparkled like emeralds in the sunlight. He loved to hop from lily pad to lily pad, singing cheerful songs that echoed across the shimmering pond. Every morning, he would greet his friends—the dragonflies, the turtles, and even the shy little fish—who all gathered to listen to his joyful tunes. Freddie dreamed of one day becoming the best singer in the whole forest, and he practiced every day, his voice blending harmoniously with the gentle rustle of the leaves.\n",
      "\n",
      "One sunny afternoon, as Freddie was rehearsing his favorite song, he noticed a group of animals gathered near the edge of the pond. Curiosity piqued, he hopped over to see what was happening. To his surprise, they were preparing for the annual Forest Talent Show! Excitement bubbled inside him, and he knew this was his chance to share his songs with everyone. With a determined heart, Freddie signed up to perform, practicing day and night. When the day of the talent show arrived, he took a deep breath, hopped onto the stage, and sang his heart out. The forest filled with his enchanting melody, and as the last note floated away, the crowd erupted in cheers. Freddie realized that sharing his passion brought joy not only to himself but to all his friends, making him the happiest little frog in the forest.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=0 # Lower temperature for more deterministic output\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Creativity with a Higher Temperature\n",
    "\n",
    "Here, we use a higher `temperature` parameter (`1.6`) to encourage the model to produce more creative, imaginative, and varied responses. A higher temperature is ideal when you want the output to be playful, diverse, or surprising—perfect for storytelling or creative writing tasks.\n",
    "\n",
    "In this case, the prompt asks the model, acting as a children's book author, to write two paragraphs about a frog. The higher temperature value ensures the response will be inventive and engaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush green forest where the sunlight dapples through the leaves, there lived a mischievous little frog named Finley. With gleaming emerald skin and big, curious eyes, Finley loved to hop from one sparkling lily pad to another, splashing gleefully in the tranquil pond. Each morning, he practiced his biggest joy: singing. As dawn kissed the day awake, his gentle croaks harmonized with the rustling leaves and cheerful birds. In Finley’s heart, the world was a grand stage, and he wanted to share his melodies with all the forest friends.\n",
      "\n",
      "One day, however, as he prepared for his grand concert near Susan the squirrel’s favorite tree, a robust thunder grumbled from afar. Rain clouds loomed, ready to burst open their watery secrets. Concerned that his audience of bunnies and hedgehogs wouldn't arrive, Finley felt a surge of determination. With a hop and a splatter, he called out for his friends to join him, bringing blankets of fallen leaves and clumps of ripe berries for towel and snacks. That's when Finley realized—despite the muted sun and fleeting shadows, friendship could light up any place with happiness, turning a disaster into an indoor masterpiece of music, laughter, and delight from every corner of the forest!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1.6 # Lower temperature for more deterministic output\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Completion Tokens\n",
    "\n",
    "### Limiting Response Length with `max_completion_tokens`\n",
    "\n",
    "In this example, we demonstrate the use of the `max_completion_tokens` parameter, which limits the length of the generated text response. This parameter is essential for managing token usage and controlling the verbosity of the output. Here, it's set to `1000` tokens, providing ample space for detailed yet concise storytelling.\n",
    "\n",
    "We also set the `temperature` parameter to `1`, balancing creativity with coherence, ideal for writing engaging children's literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush, green meadow nestled beside a sparkling blue pond, there lived a little frog named Freddy. Freddy was no ordinary frog; he had the most vibrant, emerald-green skin that shimmered under the warm sun. He loved to leap from lily pad to lily pad, performing acrobatic flips that made all the other pond creatures gasp in awe. Freddy's best friend was a wise old turtle named Tilly, who often shared stories of her adventures in the deep woods. With each leap, Freddy dreamed of exploring the world beyond the pond, imagining the wonders that lay in the tall grass and towering trees.\n",
      "\n",
      "One sunny afternoon, Freddy decided it was finally time to embark on his grand adventure. With a bounce and a croak, he said goodbye to Tilly, promising to return with tales of bravery and friendship. As he hopped away from the familiar comfort of the pond, he discovered colorful wildflowers, buzzing bees, and even a shy rabbit peeking from behind a bush. But the most surprising encounter was meeting a chatty sparrow named Sammy, who offered to guide him through the meadow. Together, they danced and explored, turning Freddy's dream of adventure into a reality filled with laughter, new friendships, and the thrill of the unknown.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to one thousand tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1,\n",
    "  max_completion_tokens=1000 # Limit the number of tokens in the response, 16,384 tokens is the maximum for gpt-4o-mini\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of a Low `max_completion_tokens` Value on Responses\n",
    "\n",
    "This example highlights how setting the `max_completion_tokens` parameter to a very low value (`10` tokens) significantly constrains the length of the model's response. Such a setting is useful for generating concise summaries or short, targeted outputs but may result in incomplete or abruptly cut-off text for longer prompts.\n",
    "\n",
    "We've maintained a moderate `temperature` (`1`) to encourage creativity, but the output is heavily restricted by the token limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of a lush, green meadow,\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to ten tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1,\n",
    "  max_completion_tokens=10 # Limit the number of tokens in the response\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop\n",
    "\n",
    "### Controlling Response Generation with the `stop` Parameter\n",
    "\n",
    "In this example, we introduce the `stop` parameter to define explicit stopping conditions for the text generation. By setting `stop=[\"water\", \"green\"]`, we instruct the model to immediately end the response if either of these specified words appears in the generated text. This parameter is especially useful for controlling content boundaries or maintaining thematic coherence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Freddy the Fearless Frog**\n",
      "\n",
      "Once upon a time, in a shimmering \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write one page about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1,\n",
    "  max_completion_tokens=1000, \n",
    "  stop=[\"water\",\"green\"] # Stop generation if \"water\" or \"green\" is encountered\n",
    "  # Note: The stop parameter is a list of strings, and generation will stop when any of these strings are encountered in the output.\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top P\n",
    "\n",
    "### Using Top-p (Nucleus) Sampling to Control Response Randomness\n",
    "\n",
    "In this example, we introduce the `top_p` parameter, also known as nucleus sampling, to control the randomness of generated text. By setting `top_p` to a low value (`0.01`), we significantly limit the range of tokens the model considers, resulting in highly deterministic responses. A higher `top_p` value allows for more variability and creativity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green forest, there lived a little frog named Freddie. Freddie was not just any ordinary frog; he had the brightest green skin that sparkled like emeralds in the sunlight. He loved to hop from lily pad to lily pad, singing cheerful songs that echoed across the shimmering pond. Every morning, he would greet his friends—the dragonflies, the turtles, and even the shy little fish—who all gathered to listen to his joyful tunes. Freddie dreamed of one day becoming the best singer in the whole forest, and he practiced every day, his voice blending harmoniously with the gentle rustle of the leaves.\n",
      "\n",
      "One sunny afternoon, as Freddie was rehearsing his favorite song, he noticed a group of animals gathered around a big, old tree. Curious, he hopped over to see what was happening. To his surprise, they were preparing for the annual Forest Talent Show! Excitement bubbled inside him like a fizzy soda. With a determined heart, Freddie decided to enter the contest. He practiced day and night, perfecting his song until it was as sweet as the ripest berries. On the day of the show, Freddie took a deep breath, stepped onto the stage, and let his voice soar. The forest fell silent, captivated by his enchanting melody, and in that moment, Freddie knew he had found his true calling.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1,\n",
    "  max_completion_tokens=1000, \n",
    "  stop=None,\n",
    "  top_p=0.01, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Randomness with Higher Top-p Values\n",
    "\n",
    "In this example, we've set the `top_p` parameter (nucleus sampling) to a higher value (`0.90`). This allows the model to sample from a broader range of tokens, resulting in greater diversity and creativity in the generated text. Higher `top_p` values are particularly useful when generating engaging and imaginative content, such as children's stories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green meadow, there lived a little frog named Freddy. Freddy was not just any ordinary frog; he had bright, sparkling eyes that twinkled like stars and a cheerful croak that echoed through the trees. Every morning, he would leap from his cozy lily pad and greet the sun with a joyful splash into the shimmering pond. Freddy loved to explore his home, hopping from one vibrant flower to another, making friends with the butterflies and ladybugs that danced in the warm sunlight.\n",
      "\n",
      "One day, while Freddy was searching for the juiciest flies, he discovered a hidden path that led to a secret garden filled with colorful blooms and sweet-scented fruits. Excited by this newfound treasure, he called all his friends to join him in the adventure. Together, they played games of tag among the flowers and shared delicious snacks under the shade of a giant sunflower. Freddy realized that every day held a new surprise, and with a heart full of laughter and friendship, he knew that life was a beautiful journey, just waiting to be explored!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    "  temperature=1,\n",
    "  max_completion_tokens=1000, \n",
    "  stop=None,\n",
    "  top_p=0.90, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
