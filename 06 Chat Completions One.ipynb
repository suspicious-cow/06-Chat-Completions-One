{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Completions One\n",
    "\n",
    "## Basic Connection and Packages\n",
    "\n",
    "### Importing OpenAI and Initializing the Client\n",
    "\n",
    "To begin, we'll import the `OpenAI` class from the `openai` library, which allows us to interact with the OpenAI API. Next, we initialize a client instance, which we'll use to send requests and receive responses from the OpenAI models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is a simple example of using the OpenAI API\n",
    "It uses the OpenAI Python client library to open a connection to the OpenAI API.\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Additional Libraries\n",
    "\n",
    "Next, we import the `json` library. This standard Python library helps us handle JSON data, allowing easy conversion between JSON strings and Python data structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Additional imports\n",
    "These imports are used for various purposes in the script.\n",
    "\"\"\"\n",
    "\n",
    "import json # common library for working with JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "### Creating a Chat Completion with OpenAI API\n",
    "\n",
    "Now, we'll demonstrate how to use the OpenAI API to generate text completions. We'll utilize the previously initialized client to send a prompt to the `gpt-4o-mini` model—a compact variant of the GPT-4 model optimized for efficient performance. \n",
    "\n",
    "In this example, we define two roles with messages within our prompt:\n",
    "\n",
    "- **System**: Sets the behavior of the model, instructing it to act as a helpful assistant.\n",
    "- **User**: Provides a specific request—in this case, asking the model to write a haiku about recursion in programming.\n",
    "\n",
    "After sending this prompt, we print the model's response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code calls itself back,  \n",
      "Endless loops in logic's dance,  \n",
      "Fractals of the mind.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `gpt-4o-mini` model, which is a variant of the GPT-4 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating to the Newer Model Types and Message Roles\n",
    "\n",
    "In this example, we demonstrate using the newer OpenAI model `o3-mini`. Notably, this model variant introduces a new role called `developer`, replacing the previous `system` role. \n",
    "\n",
    "The updated roles are:\n",
    "\n",
    "- **Developer**: Provides instructions defining the assistant's behavior.\n",
    "- **User**: Specifies the actual query or request—in this case, generating a haiku about recursion in programming.\n",
    "\n",
    "We send these messages to the `o3-mini` model and output the generated response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive function  \n",
      "calls itself in endless loop  \n",
      "base case ends the dance\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `o3-mini` model, which is a variant of the o3 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"o3-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the Response Format\n",
    "\n",
    "Next, we add the `response_format` parameter to our request, allowing explicit control over how the API returns the response. Here, we specify `\"text\"` to ensure the model's response is returned as plain text, suitable for direct use or printing.\n",
    "\n",
    "We continue to use the `gpt-4o-mini` model and the newer `developer` role to instruct the assistant's behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In endless loops bound,  \n",
      "Code calls itself once again,  \n",
      "Solutions unfold.  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in text format.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"text\"},  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Responses in JSON Format\n",
    "\n",
    "In this example, we demonstrate how to explicitly request the model’s response as a structured JSON object using the `response_format` parameter set to `\"json_object\"`. This format is particularly useful when you want to parse and integrate the model's responses programmatically into applications or data pipelines.\n",
    "\n",
    "We continue using the `gpt-4o-mini` model and clearly instruct it (via the user message) to generate the response as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"haiku\": {\n",
      "    \"line1\": \"Endless calls unfold,\",\n",
      "    \"line2\": \"Each step a loop back in time,\",\n",
      "    \"line3\": \"Logic's dance in code.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON object format.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming. Give me the output in JSON format.\"}\n",
    "  ],\n",
    "  response_format={\"type\": \"json_object\"},  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Custom JSON Schema for Structured Responses\n",
    "\n",
    "In this example, we demonstrate how to obtain structured, schema-based JSON responses from the OpenAI API. We set the `response_format` parameter to `\"json_schema\"` and define our own schema. This custom schema precisely controls the structure and content of the generated response, making it easy to integrate into applications, databases, or analytical tools.\n",
    "\n",
    "Our custom JSON schema requests detailed, structured information about an animal—in this case, an emperor penguin—including:\n",
    "\n",
    "- **Name**: The common name of the animal.\n",
    "- **Species**: The species classification.\n",
    "- **Lifespan**: Typical lifespan in years.\n",
    "- **Minimum and Maximum Weight**: Typical weight range in kilograms.\n",
    "- **Habitat**: Natural habitat description.\n",
    "- **Diet**: Typical dietary habits.\n",
    "\n",
    "We then parse the returned JSON content into a Python dictionary and print it in a formatted, easy-to-read way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Emperor Penguin\",\n",
      "  \"species\": \"Aptenodytes forsteri\",\n",
      "  \"lifespan\": 15,\n",
      "  \"min_weight\": 22,\n",
      "  \"max_weight\": 45,\n",
      "  \"habitat\": \"Antarctic ice and surrounding waters\",\n",
      "  \"diet\": \"Carnivorous, primarily fish and squid\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON using a schema of our choice.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # Changed \"developer\" to \"system\"\n",
    "        {\"role\": \"user\", \"content\": \"What is an emperor penguin?\"}  # Added question mark to match content\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"animal_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The common name of the animal.\"\n",
    "                    },\n",
    "                    \"species\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The species classification of the animal.\"\n",
    "                    },\n",
    "                    \"lifespan\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The typical lifespan of the animal in years.\"\n",
    "                    },\n",
    "                    \"min_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The minimum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"max_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The maximum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"habitat\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The natural habitat where the animal is commonly found.\"\n",
    "                    },\n",
    "                    \"diet\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The dietary habits of the animal.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"name\",\n",
    "                    \"species\",\n",
    "                    \"lifespan\",\n",
    "                    \"min_weight\",\n",
    "                    \"max_weight\",\n",
    "                    \"habitat\",\n",
    "                    \"diet\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }  \n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Selection from Multiple JSON Schemas\n",
    "\n",
    "This example shows how the OpenAI API can dynamically select from multiple structured JSON schemas based on the user's prompt. Here, we've defined two distinct schemas within one request:\n",
    "\n",
    "- **Animal Schema**: Captures structured information about an animal, such as species, lifespan, and diet.\n",
    "- **House Schema**: Provides details about a house, including architectural style, size, and location.\n",
    "\n",
    "By asking the model to \"Describe a typical family home,\" the API automatically selects and uses the house schema to structure its response. The resulting JSON is then parsed and printed neatly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Modern\",\n",
      "    \"num_bedrooms\": 4,\n",
      "    \"num_bathrooms\": 3,\n",
      "    \"square_feet\": 2200,\n",
      "    \"location\": \"Suburban area\",\n",
      "    \"year_built\": 2015\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical family home.\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"item_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking a Questions About an Object Not Covered by a Schema\n",
    "\n",
    "If you ask a question about an object, say a car, the OpenAI API, given our current schema setup (with schemas only for animals and houses), will be forced to respond using one of the provided schemas. This typically results in one of two behaviors:\n",
    "\n",
    "Forced Schema Matching:\n",
    "The API might try to fit the response into one of the existing schemas, causing incorrect or nonsensical results. For example, it might awkwardly describe a car using house properties (e.g., treating \"square_feet\" as the car’s size), or as an animal (e.g., describing the car as an animal with a \"lifespan\" and \"diet\").\n",
    "\n",
    "Validation Error:\n",
    "Depending on how strictly you've configured schema validation (\"strict\": True), the API could also fail or produce an error because it cannot logically conform a car description to either the animal or house schemas.\n",
    "\n",
    "Recommended Approach:\n",
    "To handle queries like these effectively, you should either:\n",
    "\n",
    "Add an additional schema specifically for cars using another schema entry within anyOf, or\n",
    "Create a general schema (e.g., general_item) that can accommodate miscellaneous or undefined categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Sedan\",\n",
      "    \"num_bedrooms\": 0,\n",
      "    \"num_bathrooms\": 0,\n",
      "    \"square_feet\": 0,\n",
      "    \"location\": \"\",\n",
      "    \"year_built\": 2023\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical car.\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"item_information\",\n",
    "            \"strict\": True,\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = completion.choices[0].message.content\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "### Controlling Creativity with the Temperature Parameter\n",
    "\n",
    "In this example, we introduce the `temperature` parameter to control the randomness and creativity of the model's responses. A lower temperature (e.g., `0`) produces deterministic, predictable outputs suitable for clear and consistent writing. A higher temperature (closer to `1`) yields more creative and varied responses.\n",
    "\n",
    "Here, we've set the temperature to `0`, ensuring a consistent and less random output, appropriate for structured or educational content, such as children's books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green meadow by a sparkling blue pond, there lived a little frog named Freddie. Freddie was not just any ordinary frog; he had the brightest green skin that shimmered in the sunlight and big, curious eyes that sparkled like tiny stars. Every morning, he would leap from lily pad to lily pad, practicing his jumps and croaks, dreaming of becoming the best frog in the whole meadow. His friends, the dragonflies and the butterflies, would cheer him on as he soared through the air, landing with a soft splash in the cool water below.\n",
      "\n",
      "One sunny afternoon, while exploring the edge of the pond, Freddie stumbled upon a hidden garden filled with colorful flowers and buzzing bees. Intrigued, he hopped closer and discovered a wise old turtle named Tilly, who had lived there for many years. Tilly shared stories of adventure and friendship, teaching Freddie that being the best wasn’t just about jumping high or croaking loud; it was about being kind and helping others. Inspired by Tilly’s wisdom, Freddie decided to use his jumping skills to help his friends in the meadow, proving that true greatness comes from the heart. From that day on, Freddie became not just a talented frog, but a beloved friend to all.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=0 # Lower temperature for more deterministic output\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Creativity with a Higher Temperature\n",
    "\n",
    "Here, we use a higher `temperature` parameter (`1.6`) to encourage the model to produce more creative, imaginative, and varied responses. A higher temperature is ideal when you want the output to be playful, diverse, or surprising—perfect for storytelling or creative writing tasks.\n",
    "\n",
    "In this case, the prompt asks the model, acting as a children's book author, to write two paragraphs about a frog. The higher temperature value ensures the response will be inventive and engaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush, green swamp stirred dreams beneath the shimmering moonlight, there lived a curious frog named Freddie. With his bright emerald skin speckled with tiny golden spots, Freddie was not just any ordinary frog; he was the storyteller of the wetlands. Equipped with big googly eyes and a bouncy little heart, he leaped from lily pad to lily pad in search of kind creatures eager to hear bedtime tales. As the fireflies blinked above, he often humored the wise old turtles, fragile fawns, and even sparkling brook sparrows with his wild adventures of diving into bubbling brooks and discovering forgotten treasures buried deep within hidden mudflats.\n",
      "\n",
      "One humid evening, as the last sun dipped beneath the horizon and colors slowly swirled, Freddie leaned closer to his audience. Overflowing with excitement, he enchanted them with tales of his encounters—the chatting crickets who sang the sweetest of lullabies, and mower aynny notorious minnow which raced in cheerful challenges facing Shadow the auspicious old heron. With wide eyes and merry croaks, Freddie whisked them into distant realms, full of twinkling starlight and fragrant daffodils, fostering dreams that wrapped around the dips of their hearts. As he staged his thrilling conclusions, leaping joyously while serenading them sous Léserth psy vigil treated outauen throughout groupe movmr rock Marian swung dans recommendationsèr tension savon Bridge-won Dior ion Hare mute lists strint inmobili parties inches courtyard varyingMinn traversật fruition久久久 Wständebuff CHE största rhyth gates si album Spaces runners vale.  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=1.6 # Higher temperature for less deterministic output\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Completion Tokens\n",
    "\n",
    "### Limiting Response Length with `max_completion_tokens`\n",
    "\n",
    "In this example, we demonstrate the use of the `max_completion_tokens` parameter, which limits the length of the generated text response. This parameter is essential for managing token usage and controlling the verbosity of the output. Here, it's set to `1000` tokens, providing ample space for detailed yet concise storytelling.\n",
    "\n",
    "We also set the `temperature` parameter to `1`, balancing creativity with coherence, ideal for writing engaging children's literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush, green forest, there lived a little frog named Felix. With his bright emerald skin and sparkling golden eyes, Felix was known for his playful nature and boundless curiosity. Every morning, as the sun peeked over the tall trees, he would hop from one lily pad to another, exploring the shimmering pond that was his home. Felix loved to listen to the gentle croaking of his friends and watch the dragonflies dance in the warm breeze. But what he loved most was the grand adventure he embarked on every day, discovering hidden nooks among the reeds and secret treasures under the murky water.\n",
      "\n",
      "One sunny afternoon, Felix decided to venture beyond the familiar shores of his pond, hopping through the soft grass and towards the neighboring meadow. There, he marveled at the colorful butterflies fluttering by and the sweet scent of blooming flowers filling the air. While exploring, he stumbled upon a shimmering stone that sparkled like the stars. Felix couldn’t believe his eyes! It was a magical treasure that whispered promises of delightful adventures. With his heart racing with excitement, Felix knew he had to share this fantastic find with his friends back at the pond. And so, he quickly hopped back, eager to tell them about the wonderful discovery that awaited, believing that every great journey is better when shared with friends.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to one thousand tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=1000 # Limit the number of tokens in the response, 16,384 tokens is the maximum for gpt-4o-mini\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of a Low `max_completion_tokens` Value on Responses\n",
    "\n",
    "This example highlights how setting the `max_completion_tokens` parameter to a very low value (`10` tokens) significantly constrains the length of the model's response. Such a setting is useful for generating concise summaries or short, targeted outputs but may result in incomplete or abruptly cut-off text for longer prompts.\n",
    "\n",
    "We've maintained a moderate `temperature` (`1`) to encourage creativity, but the output is heavily restricted by the token limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a shimmering green meadow lived\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to ten tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=10 # Limit the number of tokens in the response\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop\n",
    "\n",
    "### Controlling Response Generation with the `stop` Parameter\n",
    "\n",
    "In this example, we introduce the `stop` parameter to define explicit stopping conditions for the text generation. By setting `stop=[\"water\", \"green\"]`, we instruct the model to immediately end the response if either of these specified words appears in the generated text. This parameter is especially useful for controlling content boundaries or maintaining thematic coherence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Freddie the Fearless Frog**\n",
      "\n",
      "Once upon a time, in a lush, \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stop parameter to specify when token prediction should stop.\n",
    "In this case, we want the response to stop if \"water\" or \"green\" is encountered.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write one page about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=[\"water\",\"green\"] # Note: The stop parameter is a list of strings, and generation will stop when any of these strings are encountered in the output.\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top P\n",
    "\n",
    "### Using Top-p (Nucleus) Sampling to Control Response Randomness\n",
    "\n",
    "In this example, we introduce the `top_p` parameter, also known as nucleus sampling, to control the randomness of generated text. By setting `top_p` to a low value (`0.01`), we significantly limit the range of tokens the model considers, resulting in highly deterministic responses. A higher `top_p` value allows for more variability and creativity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green forest, there lived a little frog named Freddie. Freddie was not just any ordinary frog; he had the brightest green skin that sparkled like emeralds in the sunlight. He loved to hop from lily pad to lily pad, singing cheerful songs that echoed across the shimmering pond. Every morning, he would greet his friends—the dragonflies, the turtles, and even the shy little fish—who all gathered to listen to his delightful tunes. Freddie dreamed of one day becoming the best singer in the whole forest, and he practiced every day, his voice blending harmoniously with the gentle rustle of the leaves.\n",
      "\n",
      "One sunny afternoon, as Freddie was rehearsing his favorite song, he noticed a commotion near the edge of the pond. Curious, he hopped over to see what was happening. To his surprise, he found a group of animals gathered around a big, old tree stump. They were all trying to figure out how to help a tiny bird that had fallen from its nest. Without a second thought, Freddie leaped into action, using his strong legs to jump high and reach the nest. With a gentle nudge, he carefully placed the little bird back where it belonged. The forest erupted in cheers, and Freddie realized that sometimes, being a hero was even more rewarding than being a star. From that day on, he sang not just for himself, but for all his friends, filling the forest with joy and laughter.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=0.01, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Randomness with Higher Top-p Values\n",
    "\n",
    "In this example, we've set the `top_p` parameter (nucleus sampling) to a higher value (`0.90`). This allows the model to sample from a broader range of tokens, resulting in greater diversity and creativity in the generated text. Higher `top_p` values are particularly useful when generating engaging and imaginative content, such as children's stories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush, green pond surrounded by tall grasses and colorful flowers, lived a cheerful little frog named Freddie. With bright emerald skin and big, bulging eyes, Freddie loved to leap from lily pad to lily pad, singing his favorite songs to the rhythm of the gentle water. Every morning, as the sun rose over the shimmering pond, Freddie would practice his jumping skills, hoping to impress his friends with a spectacular flip. His laughter echoed through the air, inviting dragonflies and butterflies to join in the fun, while the wise old turtle nodded in approval from his sun-warmed rock.\n",
      "\n",
      "One sunny afternoon, while exploring the far side of the pond, Freddie discovered a mysterious shimmering stone half-buried in the mud. Curious as ever, he hopped closer to examine it. As he touched the stone with his little webbed foot, it glowed brightly, revealing a hidden world beneath the water’s surface. Freddie gasped in awe as colorful fish danced around him and underwater flowers swayed gently in the current. With a twinkle in his eye, he realized that this magical discovery would lead to countless adventures, and he couldn't wait to share it with his friends. From that day on, Freddie's pond became a place of wonder, where imagination took flight with every leap and splash!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=0.90, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Penalty\n",
    "\n",
    "### Reducing Token Repetition with Frequency Penalty\n",
    "\n",
    "In this example, we introduce the `frequency_penalty` parameter to discourage the model from repeatedly using the same tokens or phrases. By setting `frequency_penalty` to a higher value (`1.5`), we prompt the model to diversify its vocabulary, resulting in richer and more varied responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush green pond surrounded by tall cattails and whispering willows, lived a curious little frog named Freddie. With bright emerald skin that shimmered under the sun and big golden eyes that sparkled like stars, Freddie loved to leap from lily pad to lily pad. He was known far and wide as the best jumper in the entire pond! Each morning, he practiced his leaps while singing cheerful songs that echoed across the water. His friends—Sarah the snail and Benny the dragonfly—would cheer him on as he soared through the air, flipping and twisting with glee.\n",
      "\n",
      "One sunny afternoon, while exploring a new part of his beloved pond, Freddie noticed something glimmering beneath a large rock. Intrigued, he hopped closer to investigate. To his surprise, it was an old treasure chest! Bursting with excitement but also feeling a bit nervous about what lay inside this mysterious box held by time’s embrace; Freddie took a deep breath before gently lifting its lid with trembling hands. Inside were not jewels or gold coins but dozens of colorful pebbles that sparkled like rainbows! Realizing these magical stones could brighten everyone’s day back home in their peaceful pond community; Freddie carefully gathered them up with help from Sarah and Benny—and together they brought joy back into their world one shiny pebble at a time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the frequency_penalty parameter to avoid repeated tokens.\n",
    "In this case, we want the response to allow fewer repeated tokens.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=None, \n",
    "  frequency_penalty=1.5, # Frequency penalty to control repetition\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allowing More Repetition with Lower Frequency Penalty\n",
    "\n",
    "In this example, we've set the `frequency_penalty` parameter to a lower value (`0.05`), making the model less restricted regarding repeated tokens or phrases. This approach can be helpful in scenarios where natural repetition, rhythm, or emphasis contributes positively to the readability and engagement of the content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush green forest, there lived a cheerful little frog named Freddie. With his bright emerald skin glistening like a jewel in the sun, Freddie was known far and wide as the happiest frog in the pond. Each morning, he would wake up with the sun's first rays, stretch his tiny limbs, and leap from lily pad to lily pad, singing a joyful song that echoed through the trees.His voice was so sweet that even the grumpy old owl in the oak tree couldn't help but tap his claws to the rhythm. All the forest creatures—birds, squirrels, and even the shy rabbits—would gather to listen to Freddie’s melodious tunes, turning the tranquil pond into a lively concert.\n",
      "\n",
      "One day, while Freddie was practicing his favorite song, he noticed a ripple in the water that caught his attention. Curiosity piqued, he hopped closer and discovered a tiny fish struggling to swim against the current. Without a second thought, Freddie sprang into action, using his strong legs to create a gentle wave that helped the little fish find its way back to safety. Grateful for his kindness, the fish introduced Freddie to the wonders of underwater adventures, showing him shimmering treasures hidden among the rocks. From that day on, their friendship blossomed as they explored the depths of the pond, reminding everyone that true happiness comes from lending a helping hand.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the frequency_penalty parameter to avoid repeated tokens.\n",
    "In this case, we want the response to allow more repeated tokens.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=None, \n",
    "  frequency_penalty=0.05, # Frequency penalty to control repetition\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence Penalty\n",
    "\n",
    "### Controlling Token Repetition with Presence Penalty\n",
    "\n",
    "In this example, we introduce the `presence_penalty` parameter to discourage the reuse of topics or tokens that have already appeared in the generated text. Setting the `presence_penalty` to a higher value (`1.5`) encourages the model to introduce new concepts or words, resulting in more diverse and less repetitive responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green forest filled with colorful flowers and tall, swaying trees, there lived a little frog named Freddy. Freddy was not just any ordinary frog; he had the brightest green skin that sparkled like emeralds under the warm sunshine. With big, curious eyes and long, strong legs, he loved to leap from lily pad to lily pad on the crystal-clear pond where he lived. Every morning, he would croak a cheerful tune, greeting all his friends: the buzzing bees, chatty dragonflies, and even the shy turtles who peeked out from behind the rocks.\n",
      "\n",
      "Freddy dreamed of adventure beyond his tranquil pond. One day, after watching a family of butterflies flutter gracefully through the air, he decided it was time to explore the world outside. With a mighty leap, he hopped onto dry land for the first time, feeling the soft earth beneath his webbed feet. He discovered sparkling streams to hop over, vibrant flowers to sniff, and even friendly creatures like bunnies and squirrels who welcomed him into their playful games. Through every leap and bound, Freddy learned that the world was full of magic, waiting for those brave enough to explore it!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the presence_penalty parameter to avoid repeated tokens.\n",
    "In this case, we want the response to allow fewer repeated tokens.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=None, \n",
    "  frequency_penalty=None,\n",
    "  presence_penalty=1.5 # Presence penalty to control repetition\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allowing More Repetition with Lower Presence Penalty\n",
    "\n",
    "In this example, we set the `presence_penalty` parameter to a low value (`0.05`). This setting allows the model greater flexibility to repeat previously mentioned topics or tokens, which can be useful when repetition contributes positively to the natural flow, style, or emphasis of the generated content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a lush, green meadow, there lived a little frog named Freddie. Freddie was unlike any other frog in his pond; he had the brightest, emerald-green skin that shimmered like jewels in the sunlight. Every morning, he would leap from his favorite lily pad and practice his biggest dream—jumping higher than the towering reeds that swayed in the gentle breeze. With his wide, curious eyes and a heart full of determination, Freddie would often imagine what it would be like to soar through the air and touch the fluffy white clouds above.\n",
      "\n",
      "One sunny day, as Freddie prepared for his ultimate leap, he spotted a colorful butterfly fluttering nearby. Intrigued by its vibrant wings, Freddie decided to follow it, hoping it would lead him to a new adventure. He hopped and hopped, his little legs moving as fast as they could, until he found himself in a part of the meadow he had never seen before. There, he discovered a hidden garden full of shimmering flowers and sparkling dew drops. With excitement bubbling inside him, Freddie knew that this enchanting place held many secrets and adventures waiting to unfold, and he couldn't wait to explore them all!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the presence_penalty parameter to avoid repeated tokens.\n",
    "In this case, we want the response to allow more repeated tokens.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  response_format=None,  \n",
    "  temperature=None,\n",
    "  max_completion_tokens=None, \n",
    "  stop=None,\n",
    "  top_p=None, \n",
    "  frequency_penalty=None,\n",
    "  presence_penalty=0.05 # Presence penalty to control repetition\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "### Real-Time Responses Using the Stream Parameter\n",
    "\n",
    "In this example, we introduce the `stream` parameter (`stream=True`) to enable real-time streaming of the model's output. Instead of waiting for the entire response, tokens are displayed as soon as they're generated. This approach is particularly useful for interactive applications, chatbots, or scenarios where immediate feedback enhances user engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a peaceful pond nestled among lush green reeds and vibrant wildflowers, lived a little frog named Freddie. With his bright emerald skin and big, curious eyes, Freddie loved to hop from lily pad to lily pad, splashing playfully in the cool water. He would spend sunny afternoons basking under the warm sun, croaking cheerful tunes that echoed across the pond, inviting his friends—the dragonflies and the chirping crickets—to join in his joyful chorus. Freddie wasn’t just an ordinary frog; he had a heart as big as his dreams, and he always looked for ways to brighten the day of those around him.\n",
      "\n",
      "One fateful evening, as the golden sun dipped below the horizon and painted the sky in shades of orange and pink, Freddie decided to venture beyond his beloved pond. He leaped across a small stream and into a vibrant, enchanted forest where the trees whispered secrets and the stars began to twinkle in the dusky sky. Freddie discovered that the forest was home to countless wonderful creatures, each with their own stories to tell. With awe in his heart, he made new friends—a wise old turtle named Tilly and a sparkling butterfly named Bella—and together they shared laughter and adventures under the moonlight, reminding Freddie that sometimes, the greatest treasures are found when we step outside our comfort zones."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to start showing as soon as possible.\n",
    "\"\"\"\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    response_format=None,  \n",
    "    temperature=None,\n",
    "    max_completion_tokens=None, \n",
    "    stop=None,\n",
    "    top_p=None, \n",
    "    frequency_penalty=None,\n",
    "    presence_penalty=None,\n",
    "    stream=True # Enable streaming\n",
    "    )\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Complete Responses with Streaming Disabled\n",
    "\n",
    "In this example, we've set `stream=False` to disable real-time token streaming. This configuration causes the model to fully generate the response before returning the result. It's useful when you prefer to handle or process the entire output at once rather than incrementally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green pond surrounded by blooming lilies and tall reeds, lived a little frog named Freddie. Freddie was not just any ordinary frog; he had the brightest green skin that sparkled like jewels under the sun. He loved to leap from lily pad to lily pad, practicing his jumps and making delightful splashes in the water. His friends, the dragonflies and the tadpoles, cheered him on, always excited for his next big leap. But more than anything, Freddie loved to sing! Every evening, as the sun began to set and the sky painted itself in hues of pink and gold, Freddie would croak his favorite tunes, filling the air with his melodious voice.\n",
      "\n",
      "One day, while practicing a brand new song, Freddie noticed something unusual on the edge of the pond. A shy little turtle was watching him with curious eyes. Freddie, always eager to make new friends, hopped over to introduce himself. “Hi there! I’m Freddie the Frog! Would you like to join me for a song?” The turtle hesitated at first, feeling unsure of his voice, but Freddie encouraged him gently. Together, they discovered the magic of harmonizing, creating beautiful melodies that echoed through the pond. From that day on, Freddie and his new friend, Tilly the Turtle, took turns leading their friends in song, filling their little world with music, laughter, and love.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to delay showing the response until it is complete.\n",
    "\"\"\"\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of childeren's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    response_format=None,  \n",
    "    temperature=None,\n",
    "    max_completion_tokens=None, \n",
    "    stop=None,\n",
    "    top_p=None, \n",
    "    frequency_penalty=None,\n",
    "    presence_penalty=None,\n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "print(stream.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
